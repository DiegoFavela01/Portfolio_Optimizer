{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e3b1e4-0486-4893-9efc-08debb70266d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\envs\\dev\\lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9588\\2793913082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Import modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvix_mod\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvix_analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspy_mod\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspy_analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mecon_mod\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_econ_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "# General Libriary for steamlit and basic functions\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pyfolio as pf\n",
    "\n",
    "# Remove warning for cleaner viewing\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# Import modules\n",
    "from modules.etf_strategy_loop import etf_strategy\n",
    "from modules.optimizer_strategy_loop import optimizer_strategy\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test, X_prep_train, X_prep_test = create_train_test_tables()\n",
    "    st.write(\"Data has been prepared\")\n",
    "    # Print shapes of X_train and X_test for debugging\n",
    "    st.write(\"X_train shape:\", X_train_scaled.shape)\n",
    "    st.write(\"X_test shape:\", X_test_scaled.shape)\n",
    "    # Scale the training and test data\n",
    "    X_train_scaled, X0_train_scaled, X1_train_scaled, X2_train_scaled, y_train, y0_train, y1_train, y2_train = scale_train(X_train_scaled, X_prep_train)\n",
    "    X_test_scaled, X0_test_scaled, X1_test_scaled, X2_test_scaled, y_test, y0_test, y1_test, y2_test = scale_test(X_train_scaled, X_test_scaled, X_prep_test)\n",
    "    st.write(\"Data has been scaled\")\n",
    "    st.write(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "    st.write(\"X_train_scaled dtype:\", X_train_scaled.dtype)\n",
    "    st.write(\"y_train dtype:\", y_train.dtype)\n",
    "    # Train the regression model\n",
    "    try:\n",
    "        regression_model = Sequential()\n",
    "        input_dim = X_train_scaled.shape[1]  # Use the second dimension of X_train_scaled to determine input dimension\n",
    "        regression_model.add(Dense(32, activation='relu', input_dim=input_dim))\n",
    "        regression_model.add(Dense(1))\n",
    "        regression_model.compile(optimizer=Adam(), loss='mse')\n",
    "        X_train_scaled = X_train_scaled.astype(np.float32)\n",
    "        y_train = y_train.astype(np.float32)\n",
    "        regression_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        st.write(\"Regression model training complete\")\n",
    "    except Exception as e:\n",
    "        st.error(\"Error occurred while training the regression model.\")\n",
    "        st.error(traceback.format_exc())\n",
    "    # Train the classification model\n",
    "    try:\n",
    "        classification_model = Sequential()\n",
    "        classification_model.add(Dense(32, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
    "        classification_model.add(Dense(1, activation='sigmoid'))\n",
    "        classification_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        classification_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        st.write(\"Classification model training complete\")\n",
    "    except Exception as e:\n",
    "        st.error(\"Error occurred while training the classification model.\")\n",
    "        st.error(traceback.format_exc())\n",
    "    # Predict the returns using the regression model\n",
    "    try:\n",
    "        strategy_returns_reg = regression_model.predict(X_test_scaled).flatten()\n",
    "        st.write(\"Regression predictions generated\")\n",
    "    except Exception as e:\n",
    "        st.error(\"Error occurred while generating regression predictions.\")\n",
    "        st.error(traceback.format_exc())\n",
    "    # Predict the returns using the classification model\n",
    "    try:\n",
    "        strategy_returns_class = classification_model.predict(X_test_scaled).flatten()\n",
    "        st.write(\"Classification predictions generated\")\n",
    "    except Exception as e:\n",
    "        st.error(\"Error occurred while generating classification predictions.\")\n",
    "        st.error(traceback.format_exc())\n",
    "    # Prepare returns DataFrame\n",
    "    returns_data = {\n",
    "        'Date': X_prep_test.index,\n",
    "        'Strategy Returns (Regression)': strategy_returns_reg,\n",
    "        'Strategy Returns (Classification)': strategy_returns_class,\n",
    "        'Benchmark Returns (S&P 500)': y_test\n",
    "    }\n",
    "    returns_df = pd.DataFrame(data=returns_data, index=X_prep_test.index)\n",
    "    # Generate Pyfolio analysis for regression strategy\n",
    "    try:\n",
    "        regression_returns = returns_df['Strategy Returns (Regression)']\n",
    "        if regression_returns.empty:\n",
    "            st.warning(\"No data available for the regression strategy.\")\n",
    "        else:\n",
    "            st.write(f\"Regression Returns Shape: {regression_returns.shape}\")\n",
    "            regression_tear_sheet = pf.create_returns_tear_sheet(\n",
    "                returns=regression_returns,\n",
    "                benchmark_rets=returns_df['Benchmark Returns (S&P 500)'],\n",
    "                return_fig=True\n",
    "            )\n",
    "            # Streamlit app\n",
    "            st.title(\"Machine Learning Strategy Evaluation\")\n",
    "            st.write(\"## Performance Analysis - Regression Strategy\")\n",
    "            # Display Pyfolio returns tear sheet for regression strategy\n",
    "            st.pyplot(regression_tear_sheet)\n",
    "            # Display raw data if desired\n",
    "            if st.checkbox(\"Show Data - Regression Strategy\"):\n",
    "                st.write(returns_df[['Strategy Returns (Regression)', 'Benchmark Returns (S&P 500)']])\n",
    "    except Exception as e:\n",
    "        st.error(\"An error occurred while generating the Pyfolio analysis for the regression strategy.\")\n",
    "        st.error(traceback.format_exc())\n",
    "    # Generate Pyfolio analysis for classification strategy\n",
    "    try:\n",
    "        if returns_df[\"Strategy Returns (Classification)\"].empty:\n",
    "            st.warning(\"No data available for the classification strategy.\")\n",
    "        else:\n",
    "            classification_tear_sheet = pf.create_returns_tear_sheet(\n",
    "                returns=returns_df['Strategy Returns (Classification)'],\n",
    "                benchmark_rets=returns_df['Benchmark Returns (S&P 500)'],\n",
    "                return_fig=True\n",
    "            )\n",
    "            # Streamlit app\n",
    "            st.title(\"Machine Learning Strategy Evaluation\")\n",
    "            st.write(\"## Performance Analysis - Classification Strategy\")\n",
    "            # Display Pyfolio returns tear sheet for classification strategy\n",
    "            st.pyplot(classification_tear_sheet)\n",
    "            # Display raw data if desired\n",
    "            if st.checkbox(\"Show Data - Classification Strategy\"):\n",
    "                st.write(returns_df[['Strategy Returns (Classification)', 'Benchmark Returns (S&P 500)']])\n",
    "    except Exception as e:\n",
    "        st.error(\"An error occurred while generating the Pyfolio analysis for the classification strategy.\")\n",
    "        st.error(traceback.format_exc())\n",
    "except Exception as e:\n",
    "    st.error(\"An error occurred while running the application.\")\n",
    "    st.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6336819-8289-45ed-a86f-5bdc7f0f30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create_train_test_mod.py\n",
    "create_train_test_mod.py : import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(42)\n",
    "from .vix_mod import vix_analysis\n",
    "from .spy_mod import spy_analysis\n",
    "from .econ_mod import get_econ_data\n",
    "from .sent_mod import market_sent\n",
    "def create_train_test_tables():\n",
    "    spy_df = spy_analysis()\n",
    "    econ_df = get_econ_data()\n",
    "    vix_df = vix_analysis()\n",
    "    sentiment_df = market_sent()\n",
    "    # Set Up DataFrame for Testing\n",
    "    X_prep = pd.concat([vix_df, spy_df], axis=1)\n",
    "    X_prep['y'] = X_prep['spy_change'].shift(-1) * 100\n",
    "    X_prep = X_prep.dropna()\n",
    "    X_prep = pd.concat([X_prep, econ_df, sentiment_df], axis=1)\n",
    "    X_prep = X_prep.dropna(subset=['spy_close'])\n",
    "    X_prep[X_prep.columns] = X_prep[X_prep.columns].apply(pd.to_numeric, errors='coerce')\n",
    "    X_prep = X_prep.drop(columns=['spy_close'])\n",
    "    X_full = X_prep.drop(columns=['y'])\n",
    "    y_full = X_prep[['y']]\n",
    "    # Define train period\n",
    "    start_train = X_full.index.min()\n",
    "    end_train = dt.datetime.strptime('2020-01-01', '%Y-%m-%d').date()\n",
    "    # Define test period\n",
    "    start_test = end_train\n",
    "    end_test = X_full.index.max()\n",
    "    # Create train Data Frames\n",
    "    X_train = X_full.loc[start_train:end_train]\n",
    "    y_train = y_full.loc[start_train:end_train]\n",
    "    X_prep_train = X_prep.loc[start_train:end_train]\n",
    "    # Create test DataFrames\n",
    "    X_test = X_full.loc[start_test:end_test]\n",
    "    y_test = y_full.loc[start_test:end_test]\n",
    "    X_prep_test = X_prep.loc[start_test:end_test]\n",
    "    # Scale the training and test data using the same scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_prep_train)\n",
    "    X_test_scaled = scaler.transform(X_prep_test)\n",
    "    print(\"X_prep_train shape:\", X_prep_train.shape)\n",
    "    print(\"X_prep_test shape:\", X_prep_test.shape)\n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test, X_prep_train, X_prep_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd90a025-18a4-4aa2-b760-faa32b411c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "def scale_test(X_train, X_test, X_prep_test):\n",
    "    # Fit scaler on X_train\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train.astype(np.float32))\n",
    "    # Scale X_test\n",
    "    X_test_scaled = X_scaler.transform(X_test.astype(np.float32))\n",
    "    # Subset variables based on labels\n",
    "    X0_test_scaled = X_scaler.transform(X_test[X_prep_test['labels'] == 0].astype(np.float32))\n",
    "    X1_test_scaled = X_scaler.transform(X_test[X_prep_test['labels'] == 1].astype(np.float32))\n",
    "    X2_test_scaled = X_scaler.transform(X_test[X_prep_test['labels'] == 2].astype(np.float32))\n",
    "    y_test = X_prep_test['y'].values\n",
    "    y0_test = X_prep_test[X_prep_test['labels'] == 0]['y'].values\n",
    "    y1_test = X_prep_test[X_prep_test['labels'] == 1]['y'].values\n",
    "    y2_test = X_prep_test[X_prep_test['labels'] == 2]['y'].values\n",
    "    return (\n",
    "        X_test_scaled,\n",
    "        X0_test_scaled,\n",
    "        X1_test_scaled,\n",
    "        X2_test_scaled,\n",
    "        y_test,\n",
    "        y0_test,\n",
    "        y1_test,\n",
    "        y2_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a91e3a-52a2-47a8-9e6a-04b36be877d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
