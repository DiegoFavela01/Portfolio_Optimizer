{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90852ffb-fa59-4704-abeb-7b1bfee1cfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pandas_datareader import data as pdr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import yfinance as yf\n",
    "import scipy as sc\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a51a80-f217-42a7-bcb4-27ec7b82ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "stocks = ['TSLA','XOM']\n",
    "end1 = dt.date.today()\n",
    "start1 = end1 - dt.timedelta(days=11*365)\n",
    "start = start1.strftime('%Y-%m-%d')\n",
    "end = end1.strftime('%Y-%m-%d')\n",
    "\n",
    "stockdata = pdr.get_data_yahoo(stocks, start=start, end=end)\n",
    "stockdata = stockdata['Adj Close']\n",
    "\n",
    "returns = stockdata.pct_change().dropna(how='all').dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bb3cb47-8d09-4233-b2c1-2e6827a14c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_33832\\373590589.py:4: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  temp_table['monthly_return'] = temp_table['return'].groupby(temp_table.index.month).apply(lambda x: np.cumprod(1 + x) - 1).round(4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>return</th>\n",
       "      <th>monthly_return</th>\n",
       "      <th>monthly_std</th>\n",
       "      <th>4sma_pct_price</th>\n",
       "      <th>100sma_pct_price</th>\n",
       "      <th>bolling_top_pct</th>\n",
       "      <th>bolling_bot_pct</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-14 00:00:00-04:00</th>\n",
       "      <td>183.259995</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>-0.3346</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.039479</td>\n",
       "      <td>-0.042316</td>\n",
       "      <td>0.195518</td>\n",
       "      <td>-0.064929</td>\n",
       "      <td>1.1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-15 00:00:00-04:00</th>\n",
       "      <td>180.449997</td>\n",
       "      <td>-0.015333</td>\n",
       "      <td>-0.3448</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.014090</td>\n",
       "      <td>-0.029708</td>\n",
       "      <td>0.214416</td>\n",
       "      <td>-0.058931</td>\n",
       "      <td>1.1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 00:00:00-04:00</th>\n",
       "      <td>184.130005</td>\n",
       "      <td>0.020394</td>\n",
       "      <td>-0.3315</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.050357</td>\n",
       "      <td>0.189673</td>\n",
       "      <td>-0.082456</td>\n",
       "      <td>1.1565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-17 00:00:00-04:00</th>\n",
       "      <td>180.130005</td>\n",
       "      <td>-0.021724</td>\n",
       "      <td>-0.3460</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>-0.031174</td>\n",
       "      <td>0.207073</td>\n",
       "      <td>-0.067759</td>\n",
       "      <td>1.1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 00:00:00-04:00</th>\n",
       "      <td>183.250000</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>-0.3346</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.006876</td>\n",
       "      <td>-0.049197</td>\n",
       "      <td>0.169713</td>\n",
       "      <td>-0.082198</td>\n",
       "      <td>0.9070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-21 00:00:00-04:00</th>\n",
       "      <td>197.580002</td>\n",
       "      <td>0.078199</td>\n",
       "      <td>-0.2826</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>-0.119414</td>\n",
       "      <td>0.082230</td>\n",
       "      <td>-0.148168</td>\n",
       "      <td>0.9315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-22 00:00:00-04:00</th>\n",
       "      <td>191.149994</td>\n",
       "      <td>-0.032544</td>\n",
       "      <td>-0.3060</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.091544</td>\n",
       "      <td>0.107545</td>\n",
       "      <td>-0.116586</td>\n",
       "      <td>0.9019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 00:00:00-04:00</th>\n",
       "      <td>192.220001</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>-0.3021</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.006087</td>\n",
       "      <td>-0.098311</td>\n",
       "      <td>0.099055</td>\n",
       "      <td>-0.121614</td>\n",
       "      <td>0.8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-24 00:00:00-04:00</th>\n",
       "      <td>190.410004</td>\n",
       "      <td>-0.009416</td>\n",
       "      <td>-0.3087</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>-0.091742</td>\n",
       "      <td>0.104101</td>\n",
       "      <td>-0.112852</td>\n",
       "      <td>0.7989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-27 00:00:00-04:00</th>\n",
       "      <td>191.809998</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>-0.3036</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>-0.100234</td>\n",
       "      <td>0.089796</td>\n",
       "      <td>-0.117944</td>\n",
       "      <td>0.8743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28 00:00:00-04:00</th>\n",
       "      <td>189.190002</td>\n",
       "      <td>-0.013659</td>\n",
       "      <td>-0.3131</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>-0.089815</td>\n",
       "      <td>0.101435</td>\n",
       "      <td>-0.105971</td>\n",
       "      <td>0.9225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 00:00:00-04:00</th>\n",
       "      <td>193.880005</td>\n",
       "      <td>0.024790</td>\n",
       "      <td>-0.2961</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.013191</td>\n",
       "      <td>-0.112921</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>-0.121960</td>\n",
       "      <td>0.1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30 00:00:00-04:00</th>\n",
       "      <td>195.279999</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>-0.2910</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.014031</td>\n",
       "      <td>-0.120306</td>\n",
       "      <td>0.045198</td>\n",
       "      <td>-0.123221</td>\n",
       "      <td>0.1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 00:00:00-04:00</th>\n",
       "      <td>207.460007</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>-0.2467</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.053058</td>\n",
       "      <td>-0.171954</td>\n",
       "      <td>-0.010719</td>\n",
       "      <td>-0.178088</td>\n",
       "      <td>0.1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 00:00:00-04:00</th>\n",
       "      <td>194.770004</td>\n",
       "      <td>-0.061168</td>\n",
       "      <td>1.2789</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>-0.118122</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>-0.124690</td>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04 00:00:00-04:00</th>\n",
       "      <td>192.580002</td>\n",
       "      <td>-0.011244</td>\n",
       "      <td>1.2532</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>-0.108027</td>\n",
       "      <td>0.064318</td>\n",
       "      <td>-0.113813</td>\n",
       "      <td>0.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05 00:00:00-04:00</th>\n",
       "      <td>185.520004</td>\n",
       "      <td>-0.036660</td>\n",
       "      <td>1.1706</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>-0.073655</td>\n",
       "      <td>0.101772</td>\n",
       "      <td>-0.081103</td>\n",
       "      <td>0.2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06 00:00:00-04:00</th>\n",
       "      <td>185.059998</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>1.1652</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>-0.071658</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>-0.079629</td>\n",
       "      <td>0.1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-10 00:00:00-04:00</th>\n",
       "      <td>184.509995</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>1.1588</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.013048</td>\n",
       "      <td>-0.069512</td>\n",
       "      <td>0.107298</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>0.1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-11 00:00:00-04:00</th>\n",
       "      <td>186.789993</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>1.1855</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>-0.007067</td>\n",
       "      <td>-0.081093</td>\n",
       "      <td>0.090282</td>\n",
       "      <td>-0.076670</td>\n",
       "      <td>0.2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-12 00:00:00-04:00</th>\n",
       "      <td>180.539993</td>\n",
       "      <td>-0.033460</td>\n",
       "      <td>1.1124</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>-0.037341</td>\n",
       "      <td>0.1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-13 00:00:00-04:00</th>\n",
       "      <td>185.899994</td>\n",
       "      <td>0.029689</td>\n",
       "      <td>1.1751</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>-0.007881</td>\n",
       "      <td>-0.077495</td>\n",
       "      <td>0.087512</td>\n",
       "      <td>-0.055202</td>\n",
       "      <td>0.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-14 00:00:00-04:00</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>-0.004841</td>\n",
       "      <td>1.1645</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>-0.002392</td>\n",
       "      <td>-0.072908</td>\n",
       "      <td>0.092577</td>\n",
       "      <td>-0.049525</td>\n",
       "      <td>0.1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-17 00:00:00-04:00</th>\n",
       "      <td>187.039993</td>\n",
       "      <td>0.011027</td>\n",
       "      <td>1.1884</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>-0.012938</td>\n",
       "      <td>-0.082653</td>\n",
       "      <td>0.079455</td>\n",
       "      <td>-0.055484</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-18 00:00:00-04:00</th>\n",
       "      <td>184.309998</td>\n",
       "      <td>-0.014596</td>\n",
       "      <td>1.1565</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>-0.068174</td>\n",
       "      <td>0.095414</td>\n",
       "      <td>-0.041374</td>\n",
       "      <td>0.2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-19 00:00:00-04:00</th>\n",
       "      <td>180.589996</td>\n",
       "      <td>-0.020183</td>\n",
       "      <td>1.1129</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.020184</td>\n",
       "      <td>-0.048387</td>\n",
       "      <td>0.117749</td>\n",
       "      <td>-0.021167</td>\n",
       "      <td>0.2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-20 00:00:00-04:00</th>\n",
       "      <td>162.990005</td>\n",
       "      <td>-0.097458</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.096586</td>\n",
       "      <td>0.053130</td>\n",
       "      <td>0.258272</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>0.3322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-21 00:00:00-04:00</th>\n",
       "      <td>165.080002</td>\n",
       "      <td>0.012823</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>0.038719</td>\n",
       "      <td>0.246714</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>0.3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-24 00:00:00-04:00</th>\n",
       "      <td>162.550003</td>\n",
       "      <td>-0.015326</td>\n",
       "      <td>0.9019</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.053633</td>\n",
       "      <td>0.273763</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25 00:00:00-04:00</th>\n",
       "      <td>160.669998</td>\n",
       "      <td>-0.011566</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.013397</td>\n",
       "      <td>0.064707</td>\n",
       "      <td>0.293751</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-26 00:00:00-04:00</th>\n",
       "      <td>153.750000</td>\n",
       "      <td>-0.043070</td>\n",
       "      <td>0.7989</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.043984</td>\n",
       "      <td>0.109964</td>\n",
       "      <td>0.361408</td>\n",
       "      <td>0.012736</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-27 00:00:00-04:00</th>\n",
       "      <td>160.190002</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>-0.005618</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.305642</td>\n",
       "      <td>-0.044889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-28 00:00:00-04:00</th>\n",
       "      <td>164.309998</td>\n",
       "      <td>0.025719</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>-0.027874</td>\n",
       "      <td>0.034669</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>-0.079541</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01 00:00:00-04:00</th>\n",
       "      <td>161.830002</td>\n",
       "      <td>-0.015093</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.011185</td>\n",
       "      <td>0.049250</td>\n",
       "      <td>0.282078</td>\n",
       "      <td>-0.076216</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-02 00:00:00-04:00</th>\n",
       "      <td>160.309998</td>\n",
       "      <td>-0.009393</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.057982</td>\n",
       "      <td>0.284172</td>\n",
       "      <td>-0.077226</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-03 00:00:00-04:00</th>\n",
       "      <td>160.610001</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.055170</td>\n",
       "      <td>0.252028</td>\n",
       "      <td>-0.075723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-04 00:00:00-04:00</th>\n",
       "      <td>161.199997</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>0.050548</td>\n",
       "      <td>0.231868</td>\n",
       "      <td>-0.082460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-05 00:00:00-04:00</th>\n",
       "      <td>170.059998</td>\n",
       "      <td>0.054963</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.041250</td>\n",
       "      <td>-0.004713</td>\n",
       "      <td>0.152856</td>\n",
       "      <td>-0.127470</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08 00:00:00-04:00</th>\n",
       "      <td>171.789993</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.034199</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>0.133235</td>\n",
       "      <td>-0.135510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-09 00:00:00-04:00</th>\n",
       "      <td>169.149994</td>\n",
       "      <td>-0.015368</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.006503</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.142010</td>\n",
       "      <td>-0.121657</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-10 00:00:00-04:00</th>\n",
       "      <td>168.539993</td>\n",
       "      <td>-0.003606</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.136874</td>\n",
       "      <td>-0.117822</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11 00:00:00-04:00</th>\n",
       "      <td>172.080002</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>-0.014170</td>\n",
       "      <td>0.102072</td>\n",
       "      <td>-0.132328</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-12 00:00:00-04:00</th>\n",
       "      <td>167.979996</td>\n",
       "      <td>-0.023826</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.121938</td>\n",
       "      <td>-0.110914</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-15 00:00:00-04:00</th>\n",
       "      <td>166.350006</td>\n",
       "      <td>-0.009703</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>0.021845</td>\n",
       "      <td>0.118464</td>\n",
       "      <td>-0.098419</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-16 00:00:00-04:00</th>\n",
       "      <td>166.520004</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>0.102248</td>\n",
       "      <td>-0.094354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-17 00:00:00-04:00</th>\n",
       "      <td>173.860001</td>\n",
       "      <td>0.044079</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.029808</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>0.039419</td>\n",
       "      <td>-0.123185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-18 00:00:00-04:00</th>\n",
       "      <td>176.889999</td>\n",
       "      <td>0.017428</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.033835</td>\n",
       "      <td>-0.032452</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>-0.131641</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-19 00:00:00-04:00</th>\n",
       "      <td>180.139999</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.032128</td>\n",
       "      <td>-0.046745</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>-0.146887</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-22 00:00:00-04:00</th>\n",
       "      <td>188.869995</td>\n",
       "      <td>0.048462</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.047281</td>\n",
       "      <td>-0.086583</td>\n",
       "      <td>-0.030448</td>\n",
       "      <td>-0.196938</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-23 00:00:00-04:00</th>\n",
       "      <td>185.770004</td>\n",
       "      <td>-0.016413</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.038765</td>\n",
       "      <td>-0.015355</td>\n",
       "      <td>-0.067408</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.188122</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                price    return  monthly_return  monthly_std  \\\n",
       "Date                                                                           \n",
       "2023-03-14 00:00:00-04:00  183.259995  0.050321         -0.3346     0.041066   \n",
       "2023-03-15 00:00:00-04:00  180.449997 -0.015333         -0.3448     0.041066   \n",
       "2023-03-16 00:00:00-04:00  184.130005  0.020394         -0.3315     0.041066   \n",
       "2023-03-17 00:00:00-04:00  180.130005 -0.021724         -0.3460     0.041066   \n",
       "2023-03-20 00:00:00-04:00  183.250000  0.017321         -0.3346     0.041066   \n",
       "2023-03-21 00:00:00-04:00  197.580002  0.078199         -0.2826     0.041066   \n",
       "2023-03-22 00:00:00-04:00  191.149994 -0.032544         -0.3060     0.041066   \n",
       "2023-03-23 00:00:00-04:00  192.220001  0.005598         -0.3021     0.041066   \n",
       "2023-03-24 00:00:00-04:00  190.410004 -0.009416         -0.3087     0.041066   \n",
       "2023-03-27 00:00:00-04:00  191.809998  0.007353         -0.3036     0.041066   \n",
       "2023-03-28 00:00:00-04:00  189.190002 -0.013659         -0.3131     0.041066   \n",
       "2023-03-29 00:00:00-04:00  193.880005  0.024790         -0.2961     0.041066   \n",
       "2023-03-30 00:00:00-04:00  195.279999  0.007221         -0.2910     0.041066   \n",
       "2023-03-31 00:00:00-04:00  207.460007  0.062372         -0.2467     0.041066   \n",
       "2023-04-03 00:00:00-04:00  194.770004 -0.061168          1.2789     0.037054   \n",
       "2023-04-04 00:00:00-04:00  192.580002 -0.011244          1.2532     0.037054   \n",
       "2023-04-05 00:00:00-04:00  185.520004 -0.036660          1.1706     0.037054   \n",
       "2023-04-06 00:00:00-04:00  185.059998 -0.002480          1.1652     0.037054   \n",
       "2023-04-10 00:00:00-04:00  184.509995 -0.002972          1.1588     0.037054   \n",
       "2023-04-11 00:00:00-04:00  186.789993  0.012357          1.1855     0.037054   \n",
       "2023-04-12 00:00:00-04:00  180.539993 -0.033460          1.1124     0.037054   \n",
       "2023-04-13 00:00:00-04:00  185.899994  0.029689          1.1751     0.037054   \n",
       "2023-04-14 00:00:00-04:00  185.000000 -0.004841          1.1645     0.037054   \n",
       "2023-04-17 00:00:00-04:00  187.039993  0.011027          1.1884     0.037054   \n",
       "2023-04-18 00:00:00-04:00  184.309998 -0.014596          1.1565     0.037054   \n",
       "2023-04-19 00:00:00-04:00  180.589996 -0.020183          1.1129     0.037054   \n",
       "2023-04-20 00:00:00-04:00  162.990005 -0.097458          0.9070     0.037054   \n",
       "2023-04-21 00:00:00-04:00  165.080002  0.012823          0.9315     0.037054   \n",
       "2023-04-24 00:00:00-04:00  162.550003 -0.015326          0.9019     0.037054   \n",
       "2023-04-25 00:00:00-04:00  160.669998 -0.011566          0.8799     0.037054   \n",
       "2023-04-26 00:00:00-04:00  153.750000 -0.043070          0.7989     0.037054   \n",
       "2023-04-27 00:00:00-04:00  160.190002  0.041886          0.8743     0.037054   \n",
       "2023-04-28 00:00:00-04:00  164.309998  0.025719          0.9225     0.037054   \n",
       "2023-05-01 00:00:00-04:00  161.830002 -0.015093          0.1414     0.038765   \n",
       "2023-05-02 00:00:00-04:00  160.309998 -0.009393          0.1307     0.038765   \n",
       "2023-05-03 00:00:00-04:00  160.610001  0.001871          0.1328     0.038765   \n",
       "2023-05-04 00:00:00-04:00  161.199997  0.003673          0.1370     0.038765   \n",
       "2023-05-05 00:00:00-04:00  170.059998  0.054963          0.1995     0.038765   \n",
       "2023-05-08 00:00:00-04:00  171.789993  0.010173          0.2117     0.038765   \n",
       "2023-05-09 00:00:00-04:00  169.149994 -0.015368          0.1931     0.038765   \n",
       "2023-05-10 00:00:00-04:00  168.539993 -0.003606          0.1888     0.038765   \n",
       "2023-05-11 00:00:00-04:00  172.080002  0.021004          0.2137     0.038765   \n",
       "2023-05-12 00:00:00-04:00  167.979996 -0.023826          0.1848     0.038765   \n",
       "2023-05-15 00:00:00-04:00  166.350006 -0.009703          0.1733     0.038765   \n",
       "2023-05-16 00:00:00-04:00  166.520004  0.001022          0.1745     0.038765   \n",
       "2023-05-17 00:00:00-04:00  173.860001  0.044079          0.2263     0.038765   \n",
       "2023-05-18 00:00:00-04:00  176.889999  0.017428          0.2477     0.038765   \n",
       "2023-05-19 00:00:00-04:00  180.139999  0.018373          0.2706     0.038765   \n",
       "2023-05-22 00:00:00-04:00  188.869995  0.048462          0.3322     0.038765   \n",
       "2023-05-23 00:00:00-04:00  185.770004 -0.016413          0.3103     0.038765   \n",
       "\n",
       "                           4sma_pct_price  100sma_pct_price  bolling_top_pct  \\\n",
       "Date                                                                           \n",
       "2023-03-14 00:00:00-04:00       -0.039479         -0.042316         0.195518   \n",
       "2023-03-15 00:00:00-04:00       -0.014090         -0.029708         0.214416   \n",
       "2023-03-16 00:00:00-04:00       -0.019280         -0.050357         0.189673   \n",
       "2023-03-17 00:00:00-04:00        0.010340         -0.031174         0.207073   \n",
       "2023-03-20 00:00:00-04:00       -0.006876         -0.049197         0.169713   \n",
       "2023-03-21 00:00:00-04:00       -0.057230         -0.119414         0.082230   \n",
       "2023-03-22 00:00:00-04:00       -0.016335         -0.091544         0.107545   \n",
       "2023-03-23 00:00:00-04:00       -0.006087         -0.098311         0.099055   \n",
       "2023-03-24 00:00:00-04:00        0.012762         -0.091742         0.104101   \n",
       "2023-03-27 00:00:00-04:00       -0.002151         -0.100234         0.089796   \n",
       "2023-03-28 00:00:00-04:00        0.009078         -0.089815         0.101435   \n",
       "2023-03-29 00:00:00-04:00       -0.013191         -0.112921         0.062706   \n",
       "2023-03-30 00:00:00-04:00       -0.014031         -0.120306         0.045198   \n",
       "2023-03-31 00:00:00-04:00       -0.053058         -0.171954        -0.010719   \n",
       "2023-04-03 00:00:00-04:00        0.015801         -0.118122         0.055695   \n",
       "2023-04-04 00:00:00-04:00        0.025665         -0.108027         0.064318   \n",
       "2023-04-05 00:00:00-04:00        0.051544         -0.073655         0.101772   \n",
       "2023-04-06 00:00:00-04:00        0.023898         -0.071658         0.104019   \n",
       "2023-04-10 00:00:00-04:00        0.013048         -0.069512         0.107298   \n",
       "2023-04-11 00:00:00-04:00       -0.007067         -0.081093         0.090282   \n",
       "2023-04-12 00:00:00-04:00        0.020411         -0.050050         0.124237   \n",
       "2023-04-13 00:00:00-04:00       -0.007881         -0.077495         0.087512   \n",
       "2023-04-14 00:00:00-04:00       -0.002392         -0.072908         0.092577   \n",
       "2023-04-17 00:00:00-04:00       -0.012938         -0.082653         0.079455   \n",
       "2023-04-18 00:00:00-04:00        0.006796         -0.068174         0.095414   \n",
       "2023-04-19 00:00:00-04:00        0.020184         -0.048387         0.117749   \n",
       "2023-04-20 00:00:00-04:00        0.096586          0.053130         0.258272   \n",
       "2023-04-21 00:00:00-04:00        0.049446          0.038719         0.246714   \n",
       "2023-04-24 00:00:00-04:00        0.032313          0.053633         0.273763   \n",
       "2023-04-25 00:00:00-04:00        0.013397          0.064707         0.293751   \n",
       "2023-04-26 00:00:00-04:00        0.043984          0.109964         0.361408   \n",
       "2023-04-27 00:00:00-04:00       -0.005618          0.063187         0.305642   \n",
       "2023-04-28 00:00:00-04:00       -0.027874          0.034669         0.269841   \n",
       "2023-05-01 00:00:00-04:00       -0.011185          0.049250         0.282078   \n",
       "2023-05-02 00:00:00-04:00        0.008421          0.057982         0.284172   \n",
       "2023-05-03 00:00:00-04:00        0.007191          0.055170         0.252028   \n",
       "2023-05-04 00:00:00-04:00       -0.001318          0.050548         0.231868   \n",
       "2023-05-05 00:00:00-04:00       -0.041250         -0.004713         0.152856   \n",
       "2023-05-08 00:00:00-04:00       -0.034199         -0.014505         0.133235   \n",
       "2023-05-09 00:00:00-04:00       -0.006503          0.001361         0.142010   \n",
       "2023-05-10 00:00:00-04:00        0.007980          0.005682         0.136874   \n",
       "2023-05-11 00:00:00-04:00       -0.009821         -0.014170         0.102072   \n",
       "2023-05-12 00:00:00-04:00        0.008677          0.010949         0.121938   \n",
       "2023-05-15 00:00:00-04:00        0.014352          0.021845         0.118464   \n",
       "2023-05-16 00:00:00-04:00        0.010284          0.022527         0.102248   \n",
       "2023-05-17 00:00:00-04:00       -0.029808         -0.018555         0.039419   \n",
       "2023-05-18 00:00:00-04:00       -0.033835         -0.032452         0.011237   \n",
       "2023-05-19 00:00:00-04:00       -0.032128         -0.046745        -0.007655   \n",
       "2023-05-22 00:00:00-04:00       -0.047281         -0.086583        -0.030448   \n",
       "2023-05-23 00:00:00-04:00       -0.015355         -0.067408         0.000441   \n",
       "\n",
       "                           bolling_bot_pct       y  \n",
       "Date                                                \n",
       "2023-03-14 00:00:00-04:00        -0.064929  1.1645  \n",
       "2023-03-15 00:00:00-04:00        -0.058931  1.1884  \n",
       "2023-03-16 00:00:00-04:00        -0.082456  1.1565  \n",
       "2023-03-17 00:00:00-04:00        -0.067759  1.1129  \n",
       "2023-03-20 00:00:00-04:00        -0.082198  0.9070  \n",
       "2023-03-21 00:00:00-04:00        -0.148168  0.9315  \n",
       "2023-03-22 00:00:00-04:00        -0.116586  0.9019  \n",
       "2023-03-23 00:00:00-04:00        -0.121614  0.8799  \n",
       "2023-03-24 00:00:00-04:00        -0.112852  0.7989  \n",
       "2023-03-27 00:00:00-04:00        -0.117944  0.8743  \n",
       "2023-03-28 00:00:00-04:00        -0.105971  0.9225  \n",
       "2023-03-29 00:00:00-04:00        -0.121960  0.1414  \n",
       "2023-03-30 00:00:00-04:00        -0.123221  0.1307  \n",
       "2023-03-31 00:00:00-04:00        -0.178088  0.1328  \n",
       "2023-04-03 00:00:00-04:00        -0.124690  0.1370  \n",
       "2023-04-04 00:00:00-04:00        -0.113813  0.1995  \n",
       "2023-04-05 00:00:00-04:00        -0.081103  0.2117  \n",
       "2023-04-06 00:00:00-04:00        -0.079629  0.1931  \n",
       "2023-04-10 00:00:00-04:00        -0.075637  0.1888  \n",
       "2023-04-11 00:00:00-04:00        -0.076670  0.2137  \n",
       "2023-04-12 00:00:00-04:00        -0.037341  0.1848  \n",
       "2023-04-13 00:00:00-04:00        -0.055202  0.1733  \n",
       "2023-04-14 00:00:00-04:00        -0.049525  0.1745  \n",
       "2023-04-17 00:00:00-04:00        -0.055484  0.2263  \n",
       "2023-04-18 00:00:00-04:00        -0.041374  0.2477  \n",
       "2023-04-19 00:00:00-04:00        -0.021167  0.2706  \n",
       "2023-04-20 00:00:00-04:00         0.053404  0.3322  \n",
       "2023-04-21 00:00:00-04:00         0.017797  0.3103  \n",
       "2023-04-24 00:00:00-04:00         0.009998     NaN  \n",
       "2023-04-25 00:00:00-04:00        -0.001118     NaN  \n",
       "2023-04-26 00:00:00-04:00         0.012736     NaN  \n",
       "2023-04-27 00:00:00-04:00        -0.044889     NaN  \n",
       "2023-04-28 00:00:00-04:00        -0.079541     NaN  \n",
       "2023-05-01 00:00:00-04:00        -0.076216     NaN  \n",
       "2023-05-02 00:00:00-04:00        -0.077226     NaN  \n",
       "2023-05-03 00:00:00-04:00        -0.075723     NaN  \n",
       "2023-05-04 00:00:00-04:00        -0.082460     NaN  \n",
       "2023-05-05 00:00:00-04:00        -0.127470     NaN  \n",
       "2023-05-08 00:00:00-04:00        -0.135510     NaN  \n",
       "2023-05-09 00:00:00-04:00        -0.121657     NaN  \n",
       "2023-05-10 00:00:00-04:00        -0.117822     NaN  \n",
       "2023-05-11 00:00:00-04:00        -0.132328     NaN  \n",
       "2023-05-12 00:00:00-04:00        -0.110914     NaN  \n",
       "2023-05-15 00:00:00-04:00        -0.098419     NaN  \n",
       "2023-05-16 00:00:00-04:00        -0.094354     NaN  \n",
       "2023-05-17 00:00:00-04:00        -0.123185     NaN  \n",
       "2023-05-18 00:00:00-04:00        -0.131641     NaN  \n",
       "2023-05-19 00:00:00-04:00        -0.146887     NaN  \n",
       "2023-05-22 00:00:00-04:00        -0.196938     NaN  \n",
       "2023-05-23 00:00:00-04:00        -0.188122     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>return</th>\n",
       "      <th>monthly_return</th>\n",
       "      <th>monthly_std</th>\n",
       "      <th>4sma_pct_price</th>\n",
       "      <th>100sma_pct_price</th>\n",
       "      <th>bolling_top_pct</th>\n",
       "      <th>bolling_bot_pct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-26 00:00:00-04:00</th>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.072554</td>\n",
       "      <td>0.183861</td>\n",
       "      <td>-0.021242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27 00:00:00-04:00</th>\n",
       "      <td>-0.082188</td>\n",
       "      <td>-0.0674</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.069203</td>\n",
       "      <td>0.166724</td>\n",
       "      <td>0.295235</td>\n",
       "      <td>0.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-28 00:00:00-04:00</th>\n",
       "      <td>-0.076653</td>\n",
       "      <td>-0.1389</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.108193</td>\n",
       "      <td>0.261126</td>\n",
       "      <td>0.414331</td>\n",
       "      <td>0.076719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-29 00:00:00-04:00</th>\n",
       "      <td>0.032392</td>\n",
       "      <td>-0.1110</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>0.220313</td>\n",
       "      <td>0.369619</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02 00:00:00-04:00</th>\n",
       "      <td>-0.051291</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.045202</td>\n",
       "      <td>0.284164</td>\n",
       "      <td>0.450994</td>\n",
       "      <td>0.029177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-20 00:00:00-04:00</th>\n",
       "      <td>0.017321</td>\n",
       "      <td>-0.3346</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.006876</td>\n",
       "      <td>-0.049197</td>\n",
       "      <td>0.169713</td>\n",
       "      <td>-0.082198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-21 00:00:00-04:00</th>\n",
       "      <td>0.078199</td>\n",
       "      <td>-0.2826</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.057230</td>\n",
       "      <td>-0.119414</td>\n",
       "      <td>0.082230</td>\n",
       "      <td>-0.148168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-22 00:00:00-04:00</th>\n",
       "      <td>-0.032544</td>\n",
       "      <td>-0.3060</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>-0.091544</td>\n",
       "      <td>0.107545</td>\n",
       "      <td>-0.116586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-23 00:00:00-04:00</th>\n",
       "      <td>0.005598</td>\n",
       "      <td>-0.3021</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>-0.006087</td>\n",
       "      <td>-0.098311</td>\n",
       "      <td>0.099055</td>\n",
       "      <td>-0.121614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-24 00:00:00-04:00</th>\n",
       "      <td>-0.009416</td>\n",
       "      <td>-0.3087</td>\n",
       "      <td>0.041066</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>-0.091742</td>\n",
       "      <td>0.104101</td>\n",
       "      <td>-0.112852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             return  monthly_return  monthly_std  \\\n",
       "Date                                                               \n",
       "2018-03-26 00:00:00-04:00  0.008755          0.0161     0.041066   \n",
       "2018-03-27 00:00:00-04:00 -0.082188         -0.0674     0.041066   \n",
       "2018-03-28 00:00:00-04:00 -0.076653         -0.1389     0.041066   \n",
       "2018-03-29 00:00:00-04:00  0.032392         -0.1110     0.041066   \n",
       "2018-04-02 00:00:00-04:00 -0.051291          0.9091     0.037054   \n",
       "...                             ...             ...          ...   \n",
       "2023-03-20 00:00:00-04:00  0.017321         -0.3346     0.041066   \n",
       "2023-03-21 00:00:00-04:00  0.078199         -0.2826     0.041066   \n",
       "2023-03-22 00:00:00-04:00 -0.032544         -0.3060     0.041066   \n",
       "2023-03-23 00:00:00-04:00  0.005598         -0.3021     0.041066   \n",
       "2023-03-24 00:00:00-04:00 -0.009416         -0.3087     0.041066   \n",
       "\n",
       "                           4sma_pct_price  100sma_pct_price  bolling_top_pct  \\\n",
       "Date                                                                           \n",
       "2018-03-26 00:00:00-04:00        0.012024          0.072554         0.183861   \n",
       "2018-03-27 00:00:00-04:00        0.069203          0.166724         0.295235   \n",
       "2018-03-28 00:00:00-04:00        0.108193          0.261126         0.414331   \n",
       "2018-03-29 00:00:00-04:00        0.040159          0.220313         0.369619   \n",
       "2018-04-02 00:00:00-04:00        0.045202          0.284164         0.450994   \n",
       "...                                   ...               ...              ...   \n",
       "2023-03-20 00:00:00-04:00       -0.006876         -0.049197         0.169713   \n",
       "2023-03-21 00:00:00-04:00       -0.057230         -0.119414         0.082230   \n",
       "2023-03-22 00:00:00-04:00       -0.016335         -0.091544         0.107545   \n",
       "2023-03-23 00:00:00-04:00       -0.006087         -0.098311         0.099055   \n",
       "2023-03-24 00:00:00-04:00        0.012762         -0.091742         0.104101   \n",
       "\n",
       "                           bolling_bot_pct  \n",
       "Date                                        \n",
       "2018-03-26 00:00:00-04:00        -0.021242  \n",
       "2018-03-27 00:00:00-04:00         0.037313  \n",
       "2018-03-28 00:00:00-04:00         0.076719  \n",
       "2018-03-29 00:00:00-04:00         0.014284  \n",
       "2018-04-02 00:00:00-04:00         0.029177  \n",
       "...                                    ...  \n",
       "2023-03-20 00:00:00-04:00        -0.082198  \n",
       "2023-03-21 00:00:00-04:00        -0.148168  \n",
       "2023-03-22 00:00:00-04:00        -0.116586  \n",
       "2023-03-23 00:00:00-04:00        -0.121614  \n",
       "2023-03-24 00:00:00-04:00        -0.112852  \n",
       "\n",
       "[1259 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_table = pd.DataFrame()\n",
    "temp_table['price'] = stockdata[['TSLA']]\n",
    "temp_table['return'] = temp_table['price'].pct_change()\n",
    "temp_table['monthly_return'] = temp_table['return'].groupby(temp_table.index.month).apply(lambda x: np.cumprod(1 + x) - 1).round(4)\n",
    "temp_table['monthly_std'] = temp_table.groupby(temp_table.index.month)['return'].transform(lambda x: x.std())\n",
    "temp_table['4sma_pct_price'] = (temp_table['price'].rolling(window=4).mean()/temp_table['price']) - 1\n",
    "temp_table['100sma_pct_price'] = (temp_table['price'].rolling(window=100).mean()/temp_table['price']) - 1\n",
    "temp_table['bolling_top_pct'] = ((temp_table['price'].rolling(window=22).mean()+temp_table['price'].rolling(window=22).std()*2)/temp_table['price']) - 1\n",
    "temp_table['bolling_bot_pct'] = ((temp_table['price'].rolling(window=22).mean()-temp_table['price'].rolling(window=22).std()*2)/temp_table['price']) - 1\n",
    "temp_table['y'] = temp_table['monthly_return'].shift(-22)\n",
    "\n",
    "end1 = dt.date.today()\n",
    "start1 = end1 - dt.timedelta(days=10*365)\n",
    "start = start1.strftime('%Y-%m-%d')\n",
    "end = end1.strftime('%Y-%m-%d')\n",
    "\n",
    "temp_table = temp_table[start:end]\n",
    "display(temp_table.tail(50))\n",
    "\n",
    "end1 = dt.date.today() - dt.timedelta(days=60)\n",
    "start1 = end1 - dt.timedelta(days=5*365)\n",
    "start = start1.strftime('%Y-%m-%d')\n",
    "end = end1.strftime('%Y-%m-%d')\n",
    "\n",
    "train = temp_table[start:end]\n",
    "test = temp_table[end:]\n",
    "\n",
    "X_train = train.drop(columns=['y','price'])\n",
    "display(X_train)\n",
    "y_train = train['y']\n",
    "X_test = test.drop(columns=['y','price'])\n",
    "y_test = test['y']\n",
    "\n",
    "X_train.std(ddof=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_scaler = X_scaler.transform\n",
    "\n",
    "X_train_scaled = X_scaler(X_train)\n",
    "X_test_scaled = X_scaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2278bfb-274c-47a1-a021-efa827a5c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Packages related to machine learning\n",
    "#for nueral networs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "# fix random seed for same reproducibility as my results due to stochastic nature of start point\n",
    "K.clear_session()\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def nn_reg_model (X_train_scaled, y_train):\n",
    "    # Set Training epoch end limits, save model with the best fit during epoch testing.\n",
    "    call = [tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
    "                                                  mode='min', \n",
    "                                                  patience=35, \n",
    "                                                  verbose=1,\n",
    "                                                 ),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath='best_nn_model.h5', \n",
    "                                                    monitor='loss', \n",
    "                                                    mode='min',\n",
    "                                                    save_best_only=True, \n",
    "                                                    initil_value_threshold = .04\n",
    "                                                    )\n",
    "                ]\n",
    "    # create a loop to ensure that the fit of the machine learning model meets certain requirements\n",
    "    i=10\n",
    "    b=10\n",
    "    while (i >= 1.39) or (b >= .04):\n",
    "        # fix random seed for same reproducibility as my results due to stochastic nature of start point\n",
    "        K.clear_session()\n",
    "        tf.keras.backend.clear_session()\n",
    "        np.random.seed(42)\n",
    "        tf.random.set_seed(42)\n",
    "\n",
    "        # Create nueral network\n",
    "        nn = Sequential()\n",
    "\n",
    "        # add input layer\n",
    "        nn.add(Dense(units=100, input_dim=7, activation=\"relu\"))\n",
    "        # add first hidden layer\n",
    "        nn.add(Dense(units=150, activation=\"relu\"))\n",
    "        # add third hidden layer\n",
    "        nn.add(Dense(units=5, activation=\"relu\"))\n",
    "        # Output layer\n",
    "        nn.add(Dense(units=1, activation=\"linear\"))\n",
    "        # Compile the model\n",
    "        nn.compile(loss=\"mean_squared_error\", optimizer='adam', metrics=['mean_squared_error'])\n",
    "        try:\n",
    "            # Fit the model\n",
    "            nn_model = nn.fit(X_train_scaled, y_train, validation_split = 0.2, epochs=300, batch_size=24, callbacks = call, verbose=1)\n",
    "            b = nn_model.history['loss'][-1]\n",
    "            i = nn_model.history['val_loss'][-1]\n",
    "        except:\n",
    "            # Fit the model\n",
    "            nn_model = nn.fit(X_train_scaled, y_train, validation_split = 0.2, epochs=300, batch_size=24, callbacks = call, verbose=1)\n",
    "            b = nn_model.history['loss'][-1]\n",
    "            i = nn_model.history['val_loss'][-1]\n",
    "\n",
    "    # load a saved model\n",
    "    saved_nn_model = load_model('best_nn_model.h5')\n",
    "    \n",
    "    return saved_nn_model, nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f439c70-92da-4c07-ab4d-8af8cee6f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "42/42 [==============================] - 1s 5ms/step - loss: 0.3789 - mean_squared_error: 0.3789 - val_loss: 0.4381 - val_mean_squared_error: 0.4381\n",
      "Epoch 2/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3117 - mean_squared_error: 0.3117 - val_loss: 0.4631 - val_mean_squared_error: 0.4631\n",
      "Epoch 3/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2869 - mean_squared_error: 0.2869 - val_loss: 0.4756 - val_mean_squared_error: 0.4756\n",
      "Epoch 4/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2614 - mean_squared_error: 0.2614 - val_loss: 0.5986 - val_mean_squared_error: 0.5986\n",
      "Epoch 5/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2267 - mean_squared_error: 0.2267 - val_loss: 0.6934 - val_mean_squared_error: 0.6934\n",
      "Epoch 6/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2159 - mean_squared_error: 0.2159 - val_loss: 0.6839 - val_mean_squared_error: 0.6839\n",
      "Epoch 7/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1915 - mean_squared_error: 0.1915 - val_loss: 0.7370 - val_mean_squared_error: 0.7370\n",
      "Epoch 8/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1697 - mean_squared_error: 0.1697 - val_loss: 0.7970 - val_mean_squared_error: 0.7970\n",
      "Epoch 9/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1576 - mean_squared_error: 0.1576 - val_loss: 0.6607 - val_mean_squared_error: 0.6607\n",
      "Epoch 10/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1447 - mean_squared_error: 0.1447 - val_loss: 0.8220 - val_mean_squared_error: 0.8220\n",
      "Epoch 11/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1304 - mean_squared_error: 0.1304 - val_loss: 0.8656 - val_mean_squared_error: 0.8656\n",
      "Epoch 12/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1231 - mean_squared_error: 0.1231 - val_loss: 0.8524 - val_mean_squared_error: 0.8524\n",
      "Epoch 13/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1107 - mean_squared_error: 0.1107 - val_loss: 0.9160 - val_mean_squared_error: 0.9160\n",
      "Epoch 14/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1032 - mean_squared_error: 0.1032 - val_loss: 0.8594 - val_mean_squared_error: 0.8594\n",
      "Epoch 15/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0976 - mean_squared_error: 0.0976 - val_loss: 0.9668 - val_mean_squared_error: 0.9668\n",
      "Epoch 16/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0955 - mean_squared_error: 0.0955 - val_loss: 1.0608 - val_mean_squared_error: 1.0608\n",
      "Epoch 17/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0908 - mean_squared_error: 0.0908 - val_loss: 0.9047 - val_mean_squared_error: 0.9047\n",
      "Epoch 18/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0792 - mean_squared_error: 0.0792 - val_loss: 1.0206 - val_mean_squared_error: 1.0206\n",
      "Epoch 19/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0761 - mean_squared_error: 0.0761 - val_loss: 0.8536 - val_mean_squared_error: 0.8536\n",
      "Epoch 20/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0789 - mean_squared_error: 0.0789 - val_loss: 1.1020 - val_mean_squared_error: 1.1020\n",
      "Epoch 21/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0749 - mean_squared_error: 0.0749 - val_loss: 0.8997 - val_mean_squared_error: 0.8997\n",
      "Epoch 22/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0694 - mean_squared_error: 0.0694 - val_loss: 1.0638 - val_mean_squared_error: 1.0638\n",
      "Epoch 23/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0639 - mean_squared_error: 0.0639 - val_loss: 1.0175 - val_mean_squared_error: 1.0175\n",
      "Epoch 24/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0600 - mean_squared_error: 0.0600 - val_loss: 1.0673 - val_mean_squared_error: 1.0673\n",
      "Epoch 25/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 1.2485 - val_mean_squared_error: 1.2485\n",
      "Epoch 26/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0633 - mean_squared_error: 0.0633 - val_loss: 0.8853 - val_mean_squared_error: 0.8853\n",
      "Epoch 27/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0508 - mean_squared_error: 0.0508 - val_loss: 0.9078 - val_mean_squared_error: 0.9078\n",
      "Epoch 28/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0512 - mean_squared_error: 0.0512 - val_loss: 0.9467 - val_mean_squared_error: 0.9467\n",
      "Epoch 29/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0497 - mean_squared_error: 0.0497 - val_loss: 0.9212 - val_mean_squared_error: 0.9212\n",
      "Epoch 30/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0472 - mean_squared_error: 0.0472 - val_loss: 0.8864 - val_mean_squared_error: 0.8864\n",
      "Epoch 31/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0465 - mean_squared_error: 0.0465 - val_loss: 0.9164 - val_mean_squared_error: 0.9164\n",
      "Epoch 32/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0427 - mean_squared_error: 0.0427 - val_loss: 0.9834 - val_mean_squared_error: 0.9834\n",
      "Epoch 33/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0428 - mean_squared_error: 0.0428 - val_loss: 0.9763 - val_mean_squared_error: 0.9763\n",
      "Epoch 34/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0434 - mean_squared_error: 0.0434 - val_loss: 1.0256 - val_mean_squared_error: 1.0256\n",
      "Epoch 35/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0421 - mean_squared_error: 0.0421 - val_loss: 0.9103 - val_mean_squared_error: 0.9103\n",
      "Epoch 36/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.9864 - val_mean_squared_error: 0.9864\n",
      "Epoch 37/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.9701 - val_mean_squared_error: 0.9701\n",
      "Epoch 38/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 1.0074 - val_mean_squared_error: 1.0074\n",
      "Epoch 39/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.9281 - val_mean_squared_error: 0.9281\n",
      "Epoch 40/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.9889 - val_mean_squared_error: 0.9889\n",
      "Epoch 41/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.9600 - val_mean_squared_error: 0.9600\n",
      "Epoch 42/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.8917 - val_mean_squared_error: 0.8917\n",
      "Epoch 43/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.9841 - val_mean_squared_error: 0.9841\n",
      "Epoch 44/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.9470 - val_mean_squared_error: 0.9470\n",
      "Epoch 45/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.8976 - val_mean_squared_error: 0.8976\n",
      "Epoch 46/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.9829 - val_mean_squared_error: 0.9829\n",
      "Epoch 47/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.9791 - val_mean_squared_error: 0.9791\n",
      "Epoch 48/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.8654 - val_mean_squared_error: 0.8654\n",
      "Epoch 49/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.9433 - val_mean_squared_error: 0.9433\n",
      "Epoch 50/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.8875 - val_mean_squared_error: 0.8875\n",
      "Epoch 51/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.9111 - val_mean_squared_error: 0.9111\n",
      "Epoch 52/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.9149 - val_mean_squared_error: 0.9149\n",
      "Epoch 53/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.9413 - val_mean_squared_error: 0.9413\n",
      "Epoch 54/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.9517 - val_mean_squared_error: 0.9517\n",
      "Epoch 55/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.9581 - val_mean_squared_error: 0.9581\n",
      "Epoch 56/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.9465 - val_mean_squared_error: 0.9465\n",
      "Epoch 57/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 1.0069 - val_mean_squared_error: 1.0069\n",
      "Epoch 58/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.8069 - val_mean_squared_error: 0.8069\n",
      "Epoch 59/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.8659 - val_mean_squared_error: 0.8659\n",
      "Epoch 60/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.8627 - val_mean_squared_error: 0.8627\n",
      "Epoch 61/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.9444 - val_mean_squared_error: 0.9444\n",
      "Epoch 62/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.8784 - val_mean_squared_error: 0.8784\n",
      "Epoch 63/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.8378 - val_mean_squared_error: 0.8378\n",
      "Epoch 64/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.8422 - val_mean_squared_error: 0.8422\n",
      "Epoch 65/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.9051 - val_mean_squared_error: 0.9051\n",
      "Epoch 66/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.8070 - val_mean_squared_error: 0.8070\n",
      "Epoch 67/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.7712 - val_mean_squared_error: 0.7712\n",
      "Epoch 68/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.8573 - val_mean_squared_error: 0.8573\n",
      "Epoch 69/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.8279 - val_mean_squared_error: 0.8279\n",
      "Epoch 70/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.8745 - val_mean_squared_error: 0.8745\n",
      "Epoch 71/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.8511 - val_mean_squared_error: 0.8511\n",
      "Epoch 72/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.7864 - val_mean_squared_error: 0.7864\n",
      "Epoch 73/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.8826 - val_mean_squared_error: 0.8826\n",
      "Epoch 74/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.7753 - val_mean_squared_error: 0.7753\n",
      "Epoch 75/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.8156 - val_mean_squared_error: 0.8156\n",
      "Epoch 76/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.8645 - val_mean_squared_error: 0.8645\n",
      "Epoch 77/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.8258 - val_mean_squared_error: 0.8258\n",
      "Epoch 78/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.8202 - val_mean_squared_error: 0.8202\n",
      "Epoch 79/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.7597 - val_mean_squared_error: 0.7597\n",
      "Epoch 80/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.8002 - val_mean_squared_error: 0.8002\n",
      "Epoch 81/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.8273 - val_mean_squared_error: 0.8273\n",
      "Epoch 82/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.8617 - val_mean_squared_error: 0.8617\n",
      "Epoch 83/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.7878 - val_mean_squared_error: 0.7878\n",
      "Epoch 84/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.8229 - val_mean_squared_error: 0.8229\n",
      "Epoch 85/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.7989 - val_mean_squared_error: 0.7989\n",
      "Epoch 86/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.8217 - val_mean_squared_error: 0.8217\n",
      "Epoch 87/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.7642 - val_mean_squared_error: 0.7642\n",
      "Epoch 88/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.8044 - val_mean_squared_error: 0.8044\n",
      "Epoch 89/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.7827 - val_mean_squared_error: 0.7827\n",
      "Epoch 90/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.8603 - val_mean_squared_error: 0.8603\n",
      "Epoch 91/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.8198 - val_mean_squared_error: 0.8198\n",
      "Epoch 92/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.8343 - val_mean_squared_error: 0.8343\n",
      "Epoch 93/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.8164 - val_mean_squared_error: 0.8164\n",
      "Epoch 94/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.8243 - val_mean_squared_error: 0.8243\n",
      "Epoch 95/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.7826 - val_mean_squared_error: 0.7826\n",
      "Epoch 96/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.8018 - val_mean_squared_error: 0.8018\n",
      "Epoch 97/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.8327 - val_mean_squared_error: 0.8327\n",
      "Epoch 98/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.8124 - val_mean_squared_error: 0.8124\n",
      "Epoch 99/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.8334 - val_mean_squared_error: 0.8334\n",
      "Epoch 100/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.8142 - val_mean_squared_error: 0.8142\n",
      "Epoch 101/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.8498 - val_mean_squared_error: 0.8498\n",
      "Epoch 102/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.8161 - val_mean_squared_error: 0.8161\n",
      "Epoch 103/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.8449 - val_mean_squared_error: 0.8449\n",
      "Epoch 104/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.8010 - val_mean_squared_error: 0.8010\n",
      "Epoch 105/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.7590 - val_mean_squared_error: 0.7590\n",
      "Epoch 106/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.7978 - val_mean_squared_error: 0.7978\n",
      "Epoch 107/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.8011 - val_mean_squared_error: 0.8011\n",
      "Epoch 108/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.8283 - val_mean_squared_error: 0.8283\n",
      "Epoch 109/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.8783 - val_mean_squared_error: 0.8783\n",
      "Epoch 110/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.8270 - val_mean_squared_error: 0.8270\n",
      "Epoch 111/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.8750 - val_mean_squared_error: 0.8750\n",
      "Epoch 112/300\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.7946 - val_mean_squared_error: 0.7946\n",
      "Epoch 113/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.8310 - val_mean_squared_error: 0.8310\n",
      "Epoch 114/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.8362 - val_mean_squared_error: 0.8362\n",
      "Epoch 115/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.8421 - val_mean_squared_error: 0.8421\n",
      "Epoch 116/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.8470 - val_mean_squared_error: 0.8470\n",
      "Epoch 117/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.8197 - val_mean_squared_error: 0.8197\n",
      "Epoch 118/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.7892 - val_mean_squared_error: 0.7892\n",
      "Epoch 119/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.8242 - val_mean_squared_error: 0.8242\n",
      "Epoch 120/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.8292 - val_mean_squared_error: 0.8292\n",
      "Epoch 121/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.8268 - val_mean_squared_error: 0.8268\n",
      "Epoch 122/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.8259 - val_mean_squared_error: 0.8259\n",
      "Epoch 123/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.7949 - val_mean_squared_error: 0.7949\n",
      "Epoch 124/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.7679 - val_mean_squared_error: 0.7679\n",
      "Epoch 125/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.8189 - val_mean_squared_error: 0.8189\n",
      "Epoch 126/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.7842 - val_mean_squared_error: 0.7842\n",
      "Epoch 127/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.8534 - val_mean_squared_error: 0.8534\n",
      "Epoch 128/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.8014 - val_mean_squared_error: 0.8014\n",
      "Epoch 129/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.8046 - val_mean_squared_error: 0.8046\n",
      "Epoch 130/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.8185 - val_mean_squared_error: 0.8185\n",
      "Epoch 131/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.7787 - val_mean_squared_error: 0.7787\n",
      "Epoch 132/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.8196 - val_mean_squared_error: 0.8196\n",
      "Epoch 133/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.8145 - val_mean_squared_error: 0.8145\n",
      "Epoch 134/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.8159 - val_mean_squared_error: 0.8159\n",
      "Epoch 135/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.7839 - val_mean_squared_error: 0.7839\n",
      "Epoch 136/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.8440 - val_mean_squared_error: 0.8440\n",
      "Epoch 137/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.7997 - val_mean_squared_error: 0.7997\n",
      "Epoch 138/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.8708 - val_mean_squared_error: 0.8708\n",
      "Epoch 139/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.8210 - val_mean_squared_error: 0.8210\n",
      "Epoch 140/300\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.8361 - val_mean_squared_error: 0.8361\n",
      "Epoch 141/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.9092 - val_mean_squared_error: 0.9092\n",
      "Epoch 142/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.8268 - val_mean_squared_error: 0.8268\n",
      "Epoch 143/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.8013 - val_mean_squared_error: 0.8013\n",
      "Epoch 144/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.8260 - val_mean_squared_error: 0.8260\n",
      "Epoch 145/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.8164 - val_mean_squared_error: 0.8164\n",
      "Epoch 146/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.7715 - val_mean_squared_error: 0.7715\n",
      "Epoch 147/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.8106 - val_mean_squared_error: 0.8106\n",
      "Epoch 148/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.8444 - val_mean_squared_error: 0.8444\n",
      "Epoch 149/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.8343 - val_mean_squared_error: 0.8343\n",
      "Epoch 150/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.8058 - val_mean_squared_error: 0.8058\n",
      "Epoch 151/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.7569 - val_mean_squared_error: 0.7569\n",
      "Epoch 152/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.8015 - val_mean_squared_error: 0.8015\n",
      "Epoch 153/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.8005 - val_mean_squared_error: 0.8005\n",
      "Epoch 154/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.8045 - val_mean_squared_error: 0.8045\n",
      "Epoch 155/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.8056 - val_mean_squared_error: 0.8056\n",
      "Epoch 156/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.8224 - val_mean_squared_error: 0.8224\n",
      "Epoch 157/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.8032 - val_mean_squared_error: 0.8032\n",
      "Epoch 158/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.8115 - val_mean_squared_error: 0.8115\n",
      "Epoch 159/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.7791 - val_mean_squared_error: 0.7791\n",
      "Epoch 160/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.7917 - val_mean_squared_error: 0.7917\n",
      "Epoch 161/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.8077 - val_mean_squared_error: 0.8077\n",
      "Epoch 162/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.8046 - val_mean_squared_error: 0.8046\n",
      "Epoch 163/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.8306 - val_mean_squared_error: 0.8306\n",
      "Epoch 164/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.7252 - val_mean_squared_error: 0.7252\n",
      "Epoch 165/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.7780 - val_mean_squared_error: 0.7780\n",
      "Epoch 166/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.7918 - val_mean_squared_error: 0.7918\n",
      "Epoch 167/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.8263 - val_mean_squared_error: 0.8263\n",
      "Epoch 168/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.7948 - val_mean_squared_error: 0.7948\n",
      "Epoch 169/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.7435 - val_mean_squared_error: 0.7435\n",
      "Epoch 170/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.7989 - val_mean_squared_error: 0.7989\n",
      "Epoch 171/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.7730 - val_mean_squared_error: 0.7730\n",
      "Epoch 172/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.8165 - val_mean_squared_error: 0.8165\n",
      "Epoch 173/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.8013 - val_mean_squared_error: 0.8013\n",
      "Epoch 174/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.7945 - val_mean_squared_error: 0.7945\n",
      "Epoch 175/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.7730 - val_mean_squared_error: 0.7730\n",
      "Epoch 176/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.7780 - val_mean_squared_error: 0.7780\n",
      "Epoch 177/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.7661 - val_mean_squared_error: 0.7661\n",
      "Epoch 178/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.7524 - val_mean_squared_error: 0.7524\n",
      "Epoch 179/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.7620 - val_mean_squared_error: 0.7620\n",
      "Epoch 180/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.8146 - val_mean_squared_error: 0.8146\n",
      "Epoch 181/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.8148 - val_mean_squared_error: 0.8148\n",
      "Epoch 182/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.7712 - val_mean_squared_error: 0.7712\n",
      "Epoch 183/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.8276 - val_mean_squared_error: 0.8276\n",
      "Epoch 184/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.8406 - val_mean_squared_error: 0.8406\n",
      "Epoch 185/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.7760 - val_mean_squared_error: 0.7760\n",
      "Epoch 186/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.7831 - val_mean_squared_error: 0.7831\n",
      "Epoch 187/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.8041 - val_mean_squared_error: 0.8041\n",
      "Epoch 188/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.7951 - val_mean_squared_error: 0.7951\n",
      "Epoch 189/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.7706 - val_mean_squared_error: 0.7706\n",
      "Epoch 190/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.7769 - val_mean_squared_error: 0.7769\n",
      "Epoch 191/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.8096 - val_mean_squared_error: 0.8096\n",
      "Epoch 192/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.7719 - val_mean_squared_error: 0.7719\n",
      "Epoch 193/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.8246 - val_mean_squared_error: 0.8246\n",
      "Epoch 194/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.8315 - val_mean_squared_error: 0.8315\n",
      "Epoch 195/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.7649 - val_mean_squared_error: 0.7649\n",
      "Epoch 196/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.7988 - val_mean_squared_error: 0.7988\n",
      "Epoch 197/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.7237 - val_mean_squared_error: 0.7237\n",
      "Epoch 198/300\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.7421 - val_mean_squared_error: 0.7421\n",
      "Epoch 199/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.7796 - val_mean_squared_error: 0.7796\n",
      "Epoch 200/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.7874 - val_mean_squared_error: 0.7874\n",
      "Epoch 201/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.7620 - val_mean_squared_error: 0.7620\n",
      "Epoch 202/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.7836 - val_mean_squared_error: 0.7836\n",
      "Epoch 203/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.7482 - val_mean_squared_error: 0.7482\n",
      "Epoch 204/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.7913 - val_mean_squared_error: 0.7913\n",
      "Epoch 205/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.7999 - val_mean_squared_error: 0.7999\n",
      "Epoch 206/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.7445 - val_mean_squared_error: 0.7445\n",
      "Epoch 207/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.7812 - val_mean_squared_error: 0.7812\n",
      "Epoch 208/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.8025 - val_mean_squared_error: 0.8025\n",
      "Epoch 209/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.7880 - val_mean_squared_error: 0.7880\n",
      "Epoch 210/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.7831 - val_mean_squared_error: 0.7831\n",
      "Epoch 211/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.7842 - val_mean_squared_error: 0.7842\n",
      "Epoch 212/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.7714 - val_mean_squared_error: 0.7714\n",
      "Epoch 213/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.7692 - val_mean_squared_error: 0.7692\n",
      "Epoch 214/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.7909 - val_mean_squared_error: 0.7909\n",
      "Epoch 215/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.7536 - val_mean_squared_error: 0.7536\n",
      "Epoch 216/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.7738 - val_mean_squared_error: 0.7738\n",
      "Epoch 217/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.7700 - val_mean_squared_error: 0.7700\n",
      "Epoch 218/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.7328 - val_mean_squared_error: 0.7328\n",
      "Epoch 219/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.8284 - val_mean_squared_error: 0.8284\n",
      "Epoch 220/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.7516 - val_mean_squared_error: 0.7516\n",
      "Epoch 221/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.8332 - val_mean_squared_error: 0.8332\n",
      "Epoch 222/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.8019 - val_mean_squared_error: 0.8019\n",
      "Epoch 223/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.7841 - val_mean_squared_error: 0.7841\n",
      "Epoch 224/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.8091 - val_mean_squared_error: 0.8091\n",
      "Epoch 225/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.7702 - val_mean_squared_error: 0.7702\n",
      "Epoch 226/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.7829 - val_mean_squared_error: 0.7829\n",
      "Epoch 227/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.7689 - val_mean_squared_error: 0.7689\n",
      "Epoch 228/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.7557 - val_mean_squared_error: 0.7557\n",
      "Epoch 229/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.7506 - val_mean_squared_error: 0.7506\n",
      "Epoch 230/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.7662 - val_mean_squared_error: 0.7662\n",
      "Epoch 231/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.7527 - val_mean_squared_error: 0.7527\n",
      "Epoch 232/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.7803 - val_mean_squared_error: 0.7803\n",
      "Epoch 233/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.7621 - val_mean_squared_error: 0.7621\n",
      "Epoch 234/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.7596 - val_mean_squared_error: 0.7596\n",
      "Epoch 235/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.7521 - val_mean_squared_error: 0.7521\n",
      "Epoch 236/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.7869 - val_mean_squared_error: 0.7869\n",
      "Epoch 237/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.7737 - val_mean_squared_error: 0.7737\n",
      "Epoch 238/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.7840 - val_mean_squared_error: 0.7840\n",
      "Epoch 239/300\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.7483 - val_mean_squared_error: 0.7483\n",
      "Epoch 240/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.7694 - val_mean_squared_error: 0.7694\n",
      "Epoch 241/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.7958 - val_mean_squared_error: 0.7958\n",
      "Epoch 242/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.7932 - val_mean_squared_error: 0.7932\n",
      "Epoch 243/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.7858 - val_mean_squared_error: 0.7858\n",
      "Epoch 244/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.7880 - val_mean_squared_error: 0.7880\n",
      "Epoch 245/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.8159 - val_mean_squared_error: 0.8159\n",
      "Epoch 246/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.7629 - val_mean_squared_error: 0.7629\n",
      "Epoch 247/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.8006 - val_mean_squared_error: 0.8006\n",
      "Epoch 248/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.7751 - val_mean_squared_error: 0.7751\n",
      "Epoch 249/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.7631 - val_mean_squared_error: 0.7631\n",
      "Epoch 250/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.7497 - val_mean_squared_error: 0.7497\n",
      "Epoch 251/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.8213 - val_mean_squared_error: 0.8213\n",
      "Epoch 252/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.7914 - val_mean_squared_error: 0.7914\n",
      "Epoch 253/300\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.8218 - val_mean_squared_error: 0.8218\n",
      "Epoch 254/300\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.7271 - val_mean_squared_error: 0.7271\n",
      "Epoch 255/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.8180 - val_mean_squared_error: 0.8180\n",
      "Epoch 256/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.7361 - val_mean_squared_error: 0.7361\n",
      "Epoch 257/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.7921 - val_mean_squared_error: 0.7921\n",
      "Epoch 258/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.7600 - val_mean_squared_error: 0.7600\n",
      "Epoch 259/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.7983 - val_mean_squared_error: 0.7983\n",
      "Epoch 260/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.7734 - val_mean_squared_error: 0.7734\n",
      "Epoch 261/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.7734 - val_mean_squared_error: 0.7734\n",
      "Epoch 262/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.8506 - val_mean_squared_error: 0.8506\n",
      "Epoch 263/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.7859 - val_mean_squared_error: 0.7859\n",
      "Epoch 264/300\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.7793 - val_mean_squared_error: 0.7793\n",
      "Epoch 264: early stopping\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F3F6E610D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "[[ 1.5162473 ]\n",
      " [ 1.8498796 ]\n",
      " [ 0.9953401 ]\n",
      " [ 1.0144094 ]\n",
      " [ 0.42323977]\n",
      " [-0.16066629]\n",
      " [-0.3107633 ]\n",
      " [-0.07066716]\n",
      " [ 0.18018273]\n",
      " [ 0.25471613]\n",
      " [ 0.4466353 ]\n",
      " [ 0.25745672]\n",
      " [ 0.32786202]\n",
      " [ 0.29726616]\n",
      " [ 0.50514317]\n",
      " [ 0.29762018]\n",
      " [ 0.3011417 ]\n",
      " [-0.21149194]\n",
      " [ 0.12714162]\n",
      " [ 0.06672242]\n",
      " [ 0.2791589 ]\n",
      " [ 0.40826702]\n",
      " [ 0.16438332]\n",
      " [ 0.5684891 ]\n",
      " [ 0.9629854 ]\n",
      " [ 1.198594  ]\n",
      " [ 1.0994525 ]\n",
      " [ 0.87229073]\n",
      " [ 0.16695863]\n",
      " [ 0.07266313]\n",
      " [ 0.02470165]\n",
      " [ 0.90433943]\n",
      " [ 0.7593912 ]\n",
      " [ 0.49280846]\n",
      " [ 0.9071875 ]\n",
      " [ 0.8345771 ]\n",
      " [ 0.37305427]\n",
      " [ 0.42363822]\n",
      " [ 0.51218224]\n",
      " [ 0.87520933]\n",
      " [ 0.578906  ]]\n"
     ]
    }
   ],
   "source": [
    "saved_nn_model, nn_model = nn_reg_model(X_train_scaled, y_train)\n",
    "\n",
    "prediction1 = saved_nn_model.predict(X_test_scaled)\n",
    "print(prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8865b230-12bb-4ee1-bb12-8cb8ff5159bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-27 00:00:00-04:00</th>\n",
       "      <td>1.516247</td>\n",
       "      <td>0.8743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28 00:00:00-04:00</th>\n",
       "      <td>1.849880</td>\n",
       "      <td>0.9225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29 00:00:00-04:00</th>\n",
       "      <td>0.995340</td>\n",
       "      <td>0.1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30 00:00:00-04:00</th>\n",
       "      <td>1.014409</td>\n",
       "      <td>0.1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 00:00:00-04:00</th>\n",
       "      <td>0.423240</td>\n",
       "      <td>0.1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03 00:00:00-04:00</th>\n",
       "      <td>-0.160666</td>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04 00:00:00-04:00</th>\n",
       "      <td>-0.310763</td>\n",
       "      <td>0.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05 00:00:00-04:00</th>\n",
       "      <td>-0.070667</td>\n",
       "      <td>0.2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06 00:00:00-04:00</th>\n",
       "      <td>0.180183</td>\n",
       "      <td>0.1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-10 00:00:00-04:00</th>\n",
       "      <td>0.254716</td>\n",
       "      <td>0.1888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pred  results\n",
       "Date                                        \n",
       "2023-03-27 00:00:00-04:00  1.516247   0.8743\n",
       "2023-03-28 00:00:00-04:00  1.849880   0.9225\n",
       "2023-03-29 00:00:00-04:00  0.995340   0.1414\n",
       "2023-03-30 00:00:00-04:00  1.014409   0.1307\n",
       "2023-03-31 00:00:00-04:00  0.423240   0.1328\n",
       "2023-04-03 00:00:00-04:00 -0.160666   0.1370\n",
       "2023-04-04 00:00:00-04:00 -0.310763   0.1995\n",
       "2023-04-05 00:00:00-04:00 -0.070667   0.2117\n",
       "2023-04-06 00:00:00-04:00  0.180183   0.1931\n",
       "2023-04-10 00:00:00-04:00  0.254716   0.1888"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(prediction1, columns=['pred'], index = X_test.index) \n",
    "compare['results'] = y_test\n",
    "\n",
    "compare.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec892502-2d4a-40a8-b247-027a2883578d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
